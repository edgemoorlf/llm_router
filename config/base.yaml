# Base configuration for Azure OpenAI Proxy
name: "Azure OpenAI Proxy"
version: "1.3.0"
port: 3010

routing:
  strategy: "failover"  # failover, weighted, round_robin
  retries: 3
  timeout: 60

logging:
  level: "INFO"
  file: "logs/app.log"
  max_size: 5242880  # 5MB
  backup_count: 3
  feishu_webhook: "${FEISHU_WEBHOOK_URL}"

monitoring:
  stats_window_minutes: 5
  additional_windows: [15, 30, 60]

# Sample instance configuration - will be overridden by environment-specific configs
instances: []
  # Example instance configuration format:
  # - name: "instance1"
  #   provider_type: "azure"
  #   api_key: "${AZURE_API_KEY_1}"  # Will be replaced with env var value
  #   api_base: "https://example.openai.azure.com"
  #   api_version: "2024-08-01-preview"
  #   priority: 100
  #   weight: 100
  #   max_tpm: 240000
  #   supported_models:
  #     - "gpt-4o-mini"
  #     - "gpt-4o"
  #   model_deployments:
  #     gpt-4o-mini: "gpt4omini"
  #     gpt-4o: "gpt4o" 