# Azure OpenAI Service settings - Multiple Instances
# Primary instance
AZURE_INSTANCES=instance1,instance2,instance3

# Instance 1 configuration
AZURE_INSTANCE_1_NAME=instance1
AZURE_INSTANCE_1_API_KEY=your_azure_api_key_1
AZURE_INSTANCE_1_API_BASE=https://your-resource1.openai.azure.com
AZURE_INSTANCE_1_API_VERSION=2023-07-01-preview
AZURE_INSTANCE_1_PRIORITY=10
AZURE_INSTANCE_1_WEIGHT=100
AZURE_INSTANCE_1_MAX_TPM=240000

# Instance 2 configuration
AZURE_INSTANCE_2_NAME=instance2
AZURE_INSTANCE_2_API_KEY=your_azure_api_key_2
AZURE_INSTANCE_2_API_BASE=https://your-resource2.openai.azure.com
AZURE_INSTANCE_2_API_VERSION=2023-07-01-preview
AZURE_INSTANCE_2_PRIORITY=20
AZURE_INSTANCE_2_WEIGHT=80
AZURE_INSTANCE_2_MAX_TPM=300000

# Instance 3 configuration (add more as needed)
AZURE_INSTANCE_3_NAME=instance3
AZURE_INSTANCE_3_API_KEY=your_azure_api_key_3
AZURE_INSTANCE_3_API_BASE=https://your-resource3.openai.azure.com
AZURE_INSTANCE_3_API_VERSION=2023-07-01-preview
AZURE_INSTANCE_3_PRIORITY=30
AZURE_INSTANCE_3_WEIGHT=50
AZURE_INSTANCE_3_MAX_TPM=180000

# Fallback to legacy single instance configuration (only used if AZURE_INSTANCES is not set)
AZURE_OPENAI_API_KEY=your_azure_api_key
AZURE_OPENAI_API_BASE=https://your-resource-name.openai.azure.com
AZURE_OPENAI_API_VERSION=2023-07-01-preview

# Model deployments mapping (format: OPENAI_MODEL_NAME=AZURE_DEPLOYMENT_NAME)
MODEL_MAP_GPT4o=your-gpt4o-deployment
MODEL_MAP_GPT35TURBO=your-gpt35turbo-deployment

# Rate limiting settings
TOKEN_RATE_LIMIT=30000  # Tokens per minute
REDIS_URL=redis://localhost:6379  # Redis connection for rate limiting (optional)
USE_REDIS_RATE_LIMITER=false  # Set to true to use Redis instead of in-memory rate limiter

# Server settings
LOG_LEVEL=INFO
PORT=8000
